# Final Project
We first collected [ParsVQA-Caps, the first benchmark in Persian for Visual Question Answering and Image Captioning tasks](https://www.kaggle.com/datasets/maryamsadathashemi/parsvqacaps).

Then we evaluated few-shot and zero-shot learning on CLIP (for English) and CLIPfa (for Persian) for VQA and Image-Captioning.
